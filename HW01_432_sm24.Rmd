---
title: "Stat 432 HW 01"
author: "Name: Ahmadreza Eslaminia, netID: ae15"
date: 'Summer 2024'
output:
  pdf_document
---


Include the R code for this HW. 

```{r setup, message=FALSE,warning=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ISLR2)
library(GGally)
```

There are some useful R chunk options that you may use (for this entire semester):

* echo - Display code in output document (default = TRUE) 
* include - Include chunk in document after running (default = TRUE)
* message - display code messages in document (default = TRUE) 
* results  (default = 'markup’) 
  + 'asis’ - passthrough results 
  + 'hide’ - do not display results 
  + 'hold’ - put all results below all code
* error - Display error messages in doc (TRUE) or stop render when errors occur (FALSE) (default = FALSE) 

See R markdown cheat sheet for more information.

\newpage

## Question 1

This question relates to the College data set, which can be found in the file ```College.csv```. It contains a number of variables for 777 different universities and colleges in the US. 

### 1-1

a. Use the ```read.csv()``` function to read the data into R. Call the loaded data ```college```. Make sure that you have the directory set to the correct location for the data. 

```{r}
college <- read.csv("College.csv")
```


b. What are the variable names? 

```{r}
names(college)
```
c. Use the ```summary()``` function to produce a numerical summary of the variables in the data set.

```{r}
summary(college)
```

d. Use the ```pairs()``` function to produce a scatter plot matrix of the first ten columns or variables of the data.
(First two columns are not numeric, so start from the third column.)

```{r}
pairs(college[, 3:12])
```

e. Use the ```plot()``` function to produce side-by-side boxplots of ```Outstate``` versus ```Private```.

```{r}
boxplot(Outstate ~ Private, data = college, 
        main = "Outstate Tuition Vs Private/Public",
        xlab = "Private",
        ylab = "Outstate Tuition")
```
### 1-2

a. Is there any missing data? If so, use ```na.omit()``` to remove rows containing missing observations.

```{r}

# Check for missin valuees

any_missing <- anyNA(college)
print(paste("have missing value : ?", any_missing))

# deletes rows with missing data
college_clean <- if (anyNA(college)) na.omit(college) else college

```

b. Split your data into two parts: a testing data that contains 100 observations, and the rest as training data. You may use ```sample``` function to et the indices of the testing data. For this question, you need to set a random seed while generating this split so that the result can be replicated. Use ```4322``` as the random seed. Report the mean of ```Outstate``` of your testing data and training data, respectively.

```{r}
set.seed(4322)

test_indices <- sample(1:nrow(college_clean), 100)

# making test and training 
college_test <- college_clean[test_indices, ] 
college_train <- college_clean[-test_indices, ] 

# make mean of 'Outstate' 
mean_outstate_test <- mean(college_test$Outstate)
mean_outstate_train <- mean(college_train$Outstate)

print(paste("Mean for the tes data:", mean_outstate_test))
print(paste("Mean for the training data:", mean_outstate_train))
```

c. Use the training data to perform a EDA (Exploratory Data Analysis). Our goal is to predict the ```enroll```  of the data set. 

* Use the ```head``` function to have a look at how our data set looks like
* Use the ```GGally::ggpairs``` function to make visual plots between ```enroll``` and other variables. Include 4~5 variables in one plot. Since the goal is to predict ```enroll```, include ```enroll``` variable in all the plots. 

Note: use the *training data*!

```{r}
head(college_train)
ggpairs(college_train, columns = c("Enroll", "Apps", "Accept", "Top10perc", "F.Undergrad"))

ggpairs(college_train, columns = c("Enroll", "Outstate", "Room.Board", "PhD", "Terminal"))

ggpairs(college_train, columns = c("Enroll", "Grad.Rate", "Personal", "Books", "perc.alumni"))

ggpairs(college_train, columns = c("Enroll", "Expend", "Room.Board", "S.F.Ratio", "F.Undergrad"))

```

d. Based on your EDA analysis, pick three variables might be most relevant to  ```enroll``` (the variables may vary from student to student). Explain your reason. 

Facros; F-Undergrad - Accept  - Apps
When picking the best variables to predict Enroll, we  looking at scatter plots to see which ones show high corroletion patterns with Enroll. For example, the number of students accepted (Accept) has a strong positive correlation number with Enroll, because more acceptances usually means more students enroll. Then there’s the number of undergraduates (F.Undergrad), which is related into the overall size of the student. Also the number of applications (Apps), which is another sign of how many students might enroll; more apps generally lead to more enrollments. we can see in the plots that the number of corolation for these three factor is higher than other factors. 

\newpage

## Question 2

Load in the ```Boston``` data set. The Boston data set is
part of the ```ISLR2``` library.

a. How many rows are in this data set? How many columns? What do the rows and columns represent?
```{r}
data("Boston")

num_rows <- nrow(Boston)
num_columns <- ncol(Boston)
print(paste(" rows:", num_rows))
print(paste("columns:", num_columns))

head(Boston)
```
Each row is a town in the Boston area, and each column represents a  feature related to housing in these towns.


b. Make some pairwise scatterplots of the predictors (columns) in this data set. Adjust the `R` chunk option of the plot such that the plot is at the center and occupies 75% of the page width. Describe your findings.

Hint: https://bookdown.org/yihui/rmarkdown-cookbook/figure-size.html 


```{r, fig.align='center', out.width='75%'}
ggpairs(Boston[, c("crim", "indus", "nox", "rm", "medv")])

```
It seems between these random features correlation between the nox and indus is highest with number of 0.764 ater that the rm Vs medv is highest one with 0.695. For other pairwise combination it seems they are not so much correlated. 


c. Are any of the predictors associated with per capita crime rate? If so, explain the relationship.
```{r}
correlations <- cor(Boston)
cor_crim <- correlations["crim", ]
print(cor_crim)
```

It seems places with areas with good access to highways (rad) 0.62 , high property taxes (tax)0.58, and lots of tend to have higher crime.in next step more industry land (indus)0.40 , lstat 0.45 and more air pollution (nox)0.42,Old neighborhoods (age)0.32 , and places with higher student-teacher ratios (ptratio)0.28 have caused more crime. But, neighborhoods with big residential zones (zn)-0.2, homes with more rooms (rm)-0.21, and those further away from job centers (dis)-0.37 and the high home values (medv)-0.38 usually have lower crime rates. Being close to the Charles River (chas) doesn't really change the crime much.


d. The `chas` variable is stored as a numeric vector, so `R` has treated it as quantitative.  Convert `chas` variables into qualitative variables.Make a side-by-side boxplot of `nox` versus `chas`. 
```{r}
Boston$chas <- as.factor(Boston$chas)


boxplot(nox ~ chas, data = Boston,
        main = "NOx vs Chas",
        xlab = " (chas)",
        ylab = " (nox)",
        names = c("No", "Yes"))  # Rename levels for clarity
```
## Question 3 

$X_1$, $X_2$, $\ldots$, $X_n$ are i.i.d. ${Uniform}(0,1)$ random variables. 

a. Generate a set of $n = 100$ observations from this distribution. Only display the first 10 observations in your `R` output. Use your UIN as the seed.


```{r}
set.seed(655533073)

observations <- runif(100, min = 0, max = 1)

print(observations[1:10])
```

b. What is the sample mean and sample variance? Use your own code to calculate these quantities. That means, you should not use `mean()`, `sd()` or `var()`. 

```{r}

sample_mean <- sum(observations) / 100

sample_variance <- sum((observations - sample_mean)^2) / (100 -1)

print(paste("Sample Mean:", sample_mean))
print(paste("Sample Variance:", sample_variance))
```

c. Use default `R` functions to check if your answers in (b) are correct. 


```{r}


print(paste("Sample Mean with built0in func:", mean(observations)))
print(paste("Sample Variancewith built0in func:", var(observations)))
```
They are the same so both are correct. 

## Question 4 (GR Only)

Note that $f(x)=E[Y|X=x]$ minimizes $E[(Y-f(X))^2|X=x]$. Then what $g$ minimizes $E[|Y-g(X)||X=x]$? Justify your answer.
 
We want find the fuction $g$ that minimize the expected absolute deviation:
\[
E[|Y - g(X)||X = x]
\]

For any $x$, the function $g(x)$ that minimiz this expected absolute deviation is the conditional median of $Y$ given $X = x$. This is because the median minimizes the sum of absolute differencs from the median values. 

Mathmatically, the conditional median $m(x)$ is defined like this:
\[
\text{median}(Y|X = x) = m(x) \quad \text{so that} \quad P(Y \leq m(x) | X = x) = 0.5
\]

This means $m(x)$ is the value where half of the probability  of $Y$ goes below and half goes above, given $X = x$. By balancing values on both side, the median reduces the total sum of absolute deviations from it.

So, the function $g(x)$ that minimize $E[|Y - g(X)||X = x]$ is:
\[
g(x) = \text{median}(Y|X = x)
\]



